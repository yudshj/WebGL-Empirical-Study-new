{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T05:25:49.277149Z",
     "start_time": "2023-05-10T05:25:49.223004100Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib_venn\n",
    "import matplotlib.pyplot as plt\n",
    "DATE='0611'\n",
    "raf_path = Path('../2-9.playwright/output/raf/')\n",
    "imr = Path('./imr')\n",
    "\n",
    "imr.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def deal(path):\n",
    "    try:\n",
    "        with gzip.open(path, 'rt') as fp:\n",
    "            ret = json.load(fp)\n",
    "    except Exception as e:\n",
    "        print(path)\n",
    "        raise e\n",
    "    ret['raf_path'] = path.as_posix()\n",
    "    idx = path.as_posix().split('/')[-1].split('.')[0]\n",
    "    try:\n",
    "        ret['idx'] = int(idx)\n",
    "    except ValueError:\n",
    "        ret['idx'] = idx\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T05:12:05.053637900Z",
     "start_time": "2023-05-10T05:12:04.970478500Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0413 + 0504_czy = 0504-df_label\n",
    "df_label = pd.read_pickle('./output/0501-df_label-raf.pkl.zst.bak', compression='zstd')\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label['label_comments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_label[(df_label['label_comments'] == 'TODO') | (df_label['label_comments'] == 'File not found') | (df_label['label_comments'] == 'waiting') | (df_label['label_comments'] == 'Webdriver Error') | (df_label['label_comments'] == 'white')]\n",
    "lst = [[idx, row['url']] for idx, row in tmp.iterrows()]\n",
    "lst_json = json.dumps(lst)\n",
    "Path(\"output/0531-df_label-raf-need_interactions.json\").write_text(lst_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label2 = pd.read_pickle('./input/2023-05-09_0-30000_output.pkl').rename(columns={\n",
    "    'error': 'label_ERROR',\n",
    "    'comments': 'label_comments',\n",
    "    'use_case': 'label_usecase',\n",
    "    'need_interactions': 'label_interactions',\n",
    "})\n",
    "df_label2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label.update(df_label2)\n",
    "df_label['category'] = df_label['category'].map(lambda x: x if type(x) == list else eval(x))\n",
    "df_label.loc[df_label['label_comments'] =='domain', 'label_ERROR'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def url_essential(url: str):\n",
    "    re_pattern = r'^(http(s)?://)?(.*?)(/?index(\\.[a-z]+)?)?[#/]*$'\n",
    "    return re.match(re_pattern, url).group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = df_label.copy()\n",
    "tmp['url_essential'] = df_label['url'].map(url_essential)\n",
    "tmp.drop_duplicates(subset=['url_essential'], inplace=True)\n",
    "tmp.drop(columns=['url_essential'], inplace=True)\n",
    "tmp['label_ERROR'].value_counts().drop(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('output/0518-df_label-raf-need_interactions.json', 'w') as fp:\n",
    "    json.dump([['{:05d}'.format(idx), x['url']] for idx, x in df_label[(df_label['label_interactions']==1)|(df_label['label_comments']=='TODO')].iterrows()], fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_label['label_ERROR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T05:12:05.218500600Z",
     "start_time": "2023-05-10T05:12:05.051637900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp4 = tmp['category']\n",
    "tmp1 = tmp4.explode()\n",
    "tmp1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T05:20:15.877336100Z",
     "start_time": "2023-05-10T05:20:15.802333400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "translate = {\n",
    "    'bq': 'HTTP Archive',\n",
    "    'awwwards': 'Crawling/Galleries',\n",
    "    'tranco': 'Crawling/Top list',\n",
    "    'cssdesign': 'Crawling/Galleries',\n",
    "    'threejs': 'Crawling/Galleries',\n",
    "    'tfjs_gallery': 'Crawling/Galleries',\n",
    "    'googleart': 'Crawling/Galleries',\n",
    "    'custom': 'Crawling/Galleries',\n",
    "    'david': 'Crawling/Galleries',\n",
    "}\n",
    "tmp2 = tmp4.map(lambda x: sorted(set([translate[y] for y in x])))\n",
    "tmp2.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HERE DATASOURCE COLLECTED!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T05:24:34.703027300Z",
     "start_time": "2023-05-10T05:24:34.663310800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp2e = tmp2.explode()\n",
    "tmp2e.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2e = tmp[tmp['label_ERROR'] == 0]\n",
    "tmp2e['label_interactions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T05:25:56.657614900Z",
     "start_time": "2023-05-10T05:25:56.226940900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matplotlib_venn.venn3([set(tmp2e[tmp2e == 'Crawling/Galleries'].index), set(tmp2e[tmp2e == 'Crawling/Top list'].index), set(tmp2e[tmp2e == 'HTTP Archive'].index)], set_labels=['Crawling/Galleries', 'Crawling/Top list', 'HTTP Archive'])\n",
    "plt.savefig('fig/results_overview_coll_venn.pdf', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-02T03:38:31.389101236Z",
     "start_time": "2023-05-02T03:34:29.055599998Z"
    }
   },
   "outputs": [],
   "source": [
    "if Path(f'imr/{DATE}-df_raw_all-raf.pkl.zst').exists():\n",
    "    df = pd.read_pickle(f'imr/{DATE}-df_raw_all-raf.pkl.zst', compression='zstd')\n",
    "else:\n",
    "    df = pd.DataFrame([deal(p) for p in sorted(raf_path.glob(\"*.gz\"))]).set_index('idx')\n",
    "    df = df_label.drop(columns=['url']).join(df)\n",
    "    # df.drop(df['url'].map(url_essential).duplicated().index, inplace=True)\n",
    "    df['url'] = df['url'].astype(str)\n",
    "    df['url_essential'] = df['url'].map(url_essential)\n",
    "    df.drop_duplicates(subset=['url_essential'], inplace=True)\n",
    "    df.to_pickle(f'imr/{DATE}-df_raw_all-raf.pkl.zst', compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttt(x):\n",
    "    try:\n",
    "        return any([y['value']['data']['usedWebGL'] for y in x])\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3790982/3932600663.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp['Used WebGL'] = tmp['frame'].str['gl_raf_counters'].map(ttt)\n"
     ]
    }
   ],
   "source": [
    "tmp = df[df['label_interactions'] == 1]\n",
    "tmp['Used WebGL'] = tmp['frame'].str['gl_raf_counters'].map(ttt)\n",
    "tmp.drop(columns=['frame','events_time_hp','raf_path']).to_csv('A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-02T03:39:06.909139405Z",
     "start_time": "2023-05-02T03:38:31.388909443Z"
    }
   },
   "outputs": [],
   "source": [
    "if Path(f'imr/{DATE}-df_frame-raf.pkl.zst').exists():\n",
    "    df_frame = pd.read_pickle(f'imr/{DATE}-df_frame-raf.pkl.zst', compression='zstd')\n",
    "else:\n",
    "    df.dropna(subset=['frame'], inplace=True)\n",
    "    df_frame = df.drop(columns=['frame', 'events_time_hp']).join(pd.DataFrame(df['frame'].to_list(), index=df.index)['gl_rafs'].explode()).reset_index(drop=False).rename(columns={'index': 'idx'})\n",
    "    df_frame = df_frame.drop(columns=['gl_rafs']).join(pd.DataFrame(df_frame['gl_rafs'].str['value'].to_list(), index=df_frame.index)['data'])\n",
    "    df_frame = df_frame.drop(columns=['data']).join(pd.json_normalize(df_frame['data']).add_prefix('frame.'), how='right').dropna(subset=['frame.counter.usedWebGL']) #.drop_duplicates(subset=['frame.url']).reset_index(drop=True)\n",
    "    df_frame.to_pickle(f'imr/{DATE}-df_frame-raf.pkl.zst', compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-02T03:39:06.908969396Z"
    }
   },
   "outputs": [],
   "source": [
    "if Path(f'imr/{DATE}-df_context-raf.pkl.zst').exists():\n",
    "    df_context = pd.read_pickle(f'imr/{DATE}-df_context-raf.pkl.zst', compression='zstd')\n",
    "else:\n",
    "    df_context = df_frame.explode('frame.contextInfo').reset_index(drop=False).rename(columns={'index': 'idx-frame'})\n",
    "    df_context = df_context.drop(columns=['frame.contextInfo']).join(\n",
    "        pd.json_normalize(df_context['frame.contextInfo']).add_prefix('frame.context.'))\n",
    "    df_context.to_pickle(f'imr/{DATE}-df_context-raf.pkl.zst', compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(f'imr/{DATE}-df_context-noraf.pkl.zst').exists():\n",
    "    df_context_noraf = pd.read_pickle(f'imr/{DATE}-df_context-noraf.pkl.zst', compression='zstd')\n",
    "else:\n",
    "    df_context_noraf = df_context.drop(columns=['frame.context.rafList'])\n",
    "    df_context_noraf.to_pickle(f'imr/{DATE}-df_context-noraf.pkl.zst', compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(f'imr/{DATE}-df_shader-noraf.pkl.zst').exists():\n",
    "    df_shader = pd.read_pickle(f'imr/{DATE}-df_shader-noraf.pkl.zst', compression='zstd')\n",
    "else:\n",
    "    df_shader = df_context_noraf[['idx-frame','idx','category','label_ERROR','label_usecase','label_interactions','label_comments','url','date','raf_path','frame.url','frame.title','frame.date','frame.when','frame.context.maghsk.shaders',]].explode('frame.context.maghsk.shaders').dropna(subset=['frame.context.maghsk.shaders']).reset_index(drop=False).rename(columns={'index': 'idx-context'})\n",
    "    df_shader = df_shader.drop(columns='frame.context.maghsk.shaders').join(pd.json_normalize(df_shader['frame.context.maghsk.shaders']).add_prefix('frame.context.maghsk.shaders.')).dropna(subset=['frame.context.maghsk.shaders.source'])\n",
    "    df_shader = df_shader.explode('frame.context.maghsk.shaders.source').dropna(subset=['frame.context.maghsk.shaders.source'])\n",
    "    df_shader['frame.context.maghsk.shaders.type'] = df_shader['frame.context.maghsk.shaders.type'].astype(str).replace('35632', 'frag').replace('35633', 'vert')\n",
    "    df_shader['frame.context.maghsk.shaders.length'] = df_shader['frame.context.maghsk.shaders.source'].map(lambda x: len(x))\n",
    "    df_shader.to_pickle(f'imr/{DATE}-df_shader-noraf.pkl.zst', compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx-context', 'idx-frame', 'idx', 'category', 'label_ERROR',\n",
       "       'label_usecase', 'label_interactions', 'label_comments', 'url', 'date',\n",
       "       ...\n",
       "       'frame.context.maghsk.shaders.source.2495',\n",
       "       'frame.context.maghsk.shaders.source.2496',\n",
       "       'frame.context.maghsk.shaders.source.2497',\n",
       "       'frame.context.maghsk.shaders.source.2498',\n",
       "       'frame.context.maghsk.shaders.source.2499',\n",
       "       'frame.context.maghsk.shaders.source.2500',\n",
       "       'frame.context.maghsk.shaders.source.2501',\n",
       "       'frame.context.maghsk.shaders.source.2502',\n",
       "       'frame.context.maghsk.shaders.source.2503',\n",
       "       'frame.context.maghsk.shaders.length'],\n",
       "      dtype='object', length=2525)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shader.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_path = Path('../2-9.playwright/output/spector-tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spector_deal(p):\n",
    "    ret = json.loads(p.read_text())\n",
    "    ret['spec_path'] = p.as_posix()\n",
    "    frame = []\n",
    "    for spector in ret['spector']:\n",
    "        try:\n",
    "            frame.append({\"url\": spector['value']['url'], \"data\": [base64.b64decode(x[22:]) for x in spector['value']['data']]})\n",
    "        except:\n",
    "            pass\n",
    "    del ret['spector']\n",
    "    ret['frame'] = frame\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29242/29242 [00:49<00:00, 586.19it/s] \n"
     ]
    }
   ],
   "source": [
    "if Path(f'imr/{DATE}-df_spector.pkl.zst').exists():\n",
    "    df = pd.read_pickle(f'imr/{DATE}-df_spector.pkl.zst', compression='zstd')\n",
    "else:\n",
    "    df = pd.DataFrame([spector_deal(p) for p in tqdm.tqdm(sorted(spec_path.glob(\"*.json\")))]).set_index('idx')\n",
    "    df = df.explode('frame').dropna(subset=['frame']).reset_index(drop=False).rename(columns={'index': 'idx'})\n",
    "    df = df.drop(columns='frame').join(pd.json_normalize(df['frame']).add_prefix('frame.')).explode('frame.data').dropna(subset='frame.data').reset_index(drop=False).rename(columns={'index': 'idx-frame'})\n",
    "    df['frame.data'] = df['frame.data'].map(lambda x: json.loads(gzip.decompress(x)))\n",
    "    df.to_pickle(f'imr/{DATE}-df_spector.pkl.zst', compression='zstd')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_path = Path('../2-9.playwright/output/simple/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_simple(p):\n",
    "    with gzip.open(p, 'rt') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29241/29241 [00:07<00:00, 3656.43it/s]\n"
     ]
    }
   ],
   "source": [
    "if Path(f'imr/{DATE}-df_simple.pkl.zst').exists():\n",
    "    df = pd.read_pickle(f'imr/{DATE}-df_simple.pkl.zst', compression='zstd')\n",
    "else:\n",
    "    df_raw = pd.DataFrame([deal_simple(p) for p in tqdm.tqdm(sorted(simple_path.glob(\"*.gz\")))])\n",
    "    df = df_raw.drop(columns=['frame', 'events_time_hp']).join(pd.json_normalize(df_raw['frame']).drop(columns=['net_idle_counters','gl_simple_counters'])).explode('gl_simples').dropna(subset='gl_simples').reset_index(drop=False).rename(columns={'index': 'idx'})\n",
    "    df = df.drop(columns='gl_simples').join(pd.json_normalize(df['gl_simples'].str['value']).drop(columns=['data', 'error.name']).add_prefix('frame.')).explode('frame.data.contextInfo').dropna(subset=['frame.data.contextInfo']).reset_index(drop=False).rename(columns={'index': 'idx-frame'})\n",
    "    df = df.drop(columns=['frame.data.contextInfo']).join(pd.json_normalize(df['frame.data.contextInfo']).add_prefix('frame.data.contextInfo.'))\n",
    "    df.to_pickle(f'imr/{DATE}-df_simple.pkl.zst', compression='zstd')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_worker(p):\n",
    "    with gzip.open(p, 'rt') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_path = Path('../2-9.playwright/output/worker/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['worker.data.webgl'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3790982/2046596245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdf_worker_oc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_worker_oc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'workerOffscreenCanvasTypes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_worker_oc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'workerOffscreenCanvasTypes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error.name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'worker.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdf_frame_oc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_frame_oc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'frameOffscreenCanvasTypes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_frame_oc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frameOffscreenCanvasTypes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error.name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdf_worker_oc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'worker.data.sum'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_worker_oc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'worker.data.webgl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'worker.data.webgl2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'worker.data.2d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdf_frame_oc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frame.data.sum'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_frame_oc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frame.data.webgl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'frame.data.webgl2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'frame.data.2d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdf_worker_oc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_worker_oc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_worker_oc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'worker.data.sum'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5876\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5878\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5937\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5938\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['worker.data.webgl'] not in index\""
     ]
    }
   ],
   "source": [
    "if Path(f'imr/{DATE}-df_worker_oc.pkl.zst').exists() and Path(f'imr/{DATE}-df_frame_oc.pkl.zst').exists():\n",
    "    df_worker_oc = pd.read_pickle(f'imr/{DATE}-df_worker_oc.pkl.zst', compression='zstd')\n",
    "    df_frame_oc = pd.read_pickle(f'imr/{DATE}-df_frame_oc.pkl.zst', compression='zstd')\n",
    "else:\n",
    "    df_raw = pd.DataFrame([deal_worker(p) for p in sorted(worker_path.glob(\"*.gz\"))])\n",
    "    df = df_raw.drop(columns=['netIdleTimeout', 'events_time_hp'])\n",
    "    df_worker_oc = df.drop(columns='frameOffscreenCanvasTypes').explode('workerOffscreenCanvasTypes')\n",
    "    df_frame_oc = df.drop(columns='workerOffscreenCanvasTypes').explode('frameOffscreenCanvasTypes')\n",
    "    df_worker_oc['workerOffscreenCanvasTypes'] = df_worker_oc['workerOffscreenCanvasTypes'].str['value']\n",
    "    df_frame_oc['frameOffscreenCanvasTypes'] = df_frame_oc['frameOffscreenCanvasTypes'].str['value']\n",
    "    df_worker_oc.dropna(inplace=True)\n",
    "    df_frame_oc.dropna(inplace=True)\n",
    "    df_worker_oc = df_worker_oc.drop(columns='workerOffscreenCanvasTypes').join(pd.json_normalize(df_worker_oc['workerOffscreenCanvasTypes']).drop(columns=['data', 'error', 'error.name']).fillna(0).add_prefix('worker.')).reset_index(drop=True)\n",
    "    df_frame_oc = df_frame_oc.drop(columns='frameOffscreenCanvasTypes').join(pd.json_normalize(df_frame_oc['frameOffscreenCanvasTypes']).drop(columns=['data', 'error', 'error.name']).fillna(0).add_prefix('frame.')).reset_index(drop=True)\n",
    "    df_worker_oc['worker.data.sum'] = df_worker_oc[['worker.data.webgl', 'worker.data.webgl2', 'worker.data.2d']].sum(axis=1)\n",
    "    df_frame_oc['frame.data.sum'] = df_frame_oc[['frame.data.webgl', 'frame.data.webgl2', 'frame.data.2d']].sum(axis=1)\n",
    "    df_worker_oc = df_worker_oc[df_worker_oc['worker.data.sum'] > 0]\n",
    "    df_frame_oc = df_frame_oc[df_frame_oc['frame.data.sum'] > 0]\n",
    "    df_worker_oc.drop(columns='worker.data.sum', inplace=True)\n",
    "    df_frame_oc.drop(columns='frame.data.sum', inplace=True)\n",
    "    df_worker_oc.to_pickle(f'imr/{DATE}-df_worker_oc.pkl.zst', compression='zstd')\n",
    "    df_frame_oc.to_pickle(f'imr/{DATE}-df_frame_oc.pkl.zst', compression='zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
